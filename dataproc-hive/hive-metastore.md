# Настройка внешней базы данных Hive Metastore для сервиса Yandex Data Proc

[Сервис Yandex Data Proc](https://cloud.yandex.ru/services/data-proc) включает в себя технологии [Apache Hive](https://hive.apache.org) и [Apache Spark](https://spark.apache.org), и использует компонент Hive Metastore для ведения информации о структуре таблиц, форматах хранения их данных, размещении файлов с данными.

Информация, с которой работает Hive Metastore, хранится в базе данных [одного из поддерживаемых типов](https://cwiki.apache.org/confluence/display/Hive/AdminManual+Metastore+Administration#AdminManualMetastoreAdministration-SupportedBackendDatabasesforMetastore). По умолчанию Yandex Data Proc размещает базу данных Hive Metastore под управлением PostgreSQL на мастер-сервере кластера Data Proc, но такая конфигурация не является полностью отказоустойчивой, имеет ограниченную масштабируемость и не позволяет организовать полноценное резервное копирование данных. Кроме того, использование отдельных копий данных Hive Metastore в каждом кластере Data Proc не позволяет организовать обработку единого массива данных с использованием нескольких кластеров.

Вместо использования встроенной базы данных Hive Metastore, на сегодня (до готовности в Yandex Cloud управляемого сервиса Hive Metastore) рекомендуется применять внешнюю базу данных, в виде сервиса [Yandex Managed Service for PostgreSQL](https://cloud.yandex.ru/services/managed-postgresql). Тем самым эффективно решаются вопросы отказоустойчивости, масштабирования и резервного копирования базы данных Hive Metastore. Время жизни метаданных в такой конфигурации превышает время существования отдельных кластеров Data Proc, и возникает возможность согласованного доступа из нескольких кластеров Data Proc к общему массиву данных, размещённому в [объектном хранилище Yandex Object Storage](https://cloud.yandex.ru/services/storage).

Настройка внешней базы данных Hive Metastore выполняется в следующем порядке:
1. Создание и настройка сервиса PostgreSQL
2. Инициализация базы данных Hive Metastore
3. Запуск кластеров Data Proc с использованием внешней базы данных Hive Metastore

## 1. Создание и настройка сервиса PostgreSQL

Сервис PostgreSQL в Yandex Cloud создаётся в соответствии с инструкциями в [официальной документации сервиса](https://cloud.yandex.ru/docs/managed-postgresql/operations/cluster-create).

Рекомендуемые настройки сервиса для типовой инсталляции Hive Metastore:
* имя кластера - осмысленное наименование кластера, например `metastore1`;
* тип окружения - `PRODUCTION`;
* версия СУБД - `14`;
* класс хоста - `s3-c2-m8` для небольшой инсталляции Data Proc, не менее `s3-c4-m16` для нагруженной инсталляции;
* тип диска - реплицируемые сетевые SSD диски `network-ssd`, объём не менее 30 Гбайт;
* имя базы данных - `hive`;
* логин пользователя - `hive`;
* пароль - сгенерированное случайное значение длиною не менее 12 букв и цифр;
* локали сортировки и набора символов - по умолчанию (`C`);
* сеть и группа безопасности - дающие возможность доступа со стороны кластеров Data Proc;
* размещение хостов - без предоставления публичного доступа:
    * в 3 зонах доступности для максимальной отказоустойчивости,
    * в зоне, где работают кластера Data Proc, если максимальная отказоустойчивость не требуется;
* окно обслуживания - период минимальной активности кластеров Data Proc;
* разрешить доступ из консоли управления;
* разрешить сбор статистик;
* режим работы менеджера подключений - `session`;
* защита от удаления - включить для продуктивных окружений.

## 2. Инициализация базы данных Hive Metastore

Для выполнения инициализации базы данных Hive Metastore необходим кластер Data Proc, для которого включён компонент Hive. Можно использовать любой из существующих кластеров, либо создать специальный временный кластер. Пример команды для создания временного кластера Data Proc с использованием YC CLI приведён ниже:

```bash
yc dataproc cluster create hive-ms-init \
  --zone ru-central1-b \
  --service-account-name dp1 \
  --version 2.0.58 --ui-proxy \
  --services yarn,tez,hive \
  --bucket dproc1 \
  --subcluster name="master",role='masternode',resource-preset='s3-c2-m8',disk-type='network-hdd',disk-size=100,hosts-count=1,subnet-name=default-ru-central1-b \
  --subcluster name="compute",role='computenode',resource-preset='s3-c2-m8',disk-type='network-hdd',disk-size=100,hosts-count=1,max-hosts-count=1,subnet-name=default-ru-central1-b \
  --ssh-public-keys-file ssh-keys.tmp
```

Перед созданием временного кластера Data Proc должен быть создан бакет Object Storage (в примере выше - `dproc1`) и сервисный аккаунт, обладающий правами доступа к этому бакету (в примере выше - `dp1`). Также необходимо выбрать подсеть для работы кластера (в примере - `default-ru-central1-b`).

Доступ к кластеру будет осуществляться с промежуточного хоста, который должен быть предварительно создан (например, в виде виртуальной машины под управлением ОС Linux), и подключен к необходимой подсети и группе безопасности. На промежуточном хосте должен быть сгенерирован SSH-ключ, публичная часть ключа используется при создании временного кластера Data Proc (в примере команды выше ключ записан в файл `ssh-keys.tmp`).

## 3. Запуск кластеров Data Proc с использованием внешней базы данных Hive Metastore

# Настройка внешнего Hive Metastore

