# Сбор логов Yandex Data Proc и доступ к логам

## 1. Логи, собираемые в Yandex Cloud Logging

Сервис [Yandex Data Proc](https://cloud.yandex.com/ru/services/data-proc) отправляет логи компонентов в [Yandex Cloud Logging](https://cloud.yandex.com/ru/services/logging). Каждая запись снабжается дополнительными атрибутами, позволяющими определить конкретный кластер Data Proc, компонент и другие характеристики источника логов.

[Для доступа к логам](https://cloud.yandex.ru/ru/docs/logging/operations/read-logs) можно использовать интерфейс Cloud Logging в Консоли Yandex Cloud, а также команду для доступа к логам в YC CLI.

При поиске информации важно задать корректные критерии фильтрации, чтобы не пропустить нужную информацию среди потока посторонних записей лога. Одним из инструментов первичной фильтрации является создание отдельной группы логирования для Data Proc, что позволяет сразу же отбросить логи других сервисов (например, бессерверных функций или контейнеров).

Для ограничения диапазона времени поиска поддерживаются фильтры на момент времени (значения задаются во временной зоне UTC), для YC CLI используются параметры `--since чч:мм:сс` и `--until чч:мм:сс` (метки времени указываются в UTC, для указания даты используется формат `гггг-мм-ддTчч:мм:ссZ`). При выводе логов по умолчанию применяются ограничения на количество записей. Ограничение применяется после фильтрации по диапазону времени, но до фильтра по другим атрибутам. Для YC CLI есть возможность увеличить это ограничение с помощью парамера `--limit N`, где `N` - желаемое максимальное значение лимита. 

При использовании YC CLI для вывода деталей по событиям необходимо указать параметр `--format json`. Этот режим вывода может быть неудобен для анализа логов от одного конкретного компонента, поэтому по умолчанию выводится только текстовая часть события лога.

Ниже приведены рецепты некоторых типовых фильтров для отбора данных о функционировании компонентов Data Proc и о выполнении заданий. Предполагаем, что `mzinal-dataproc1` - это название используемой группы логирования.

### 1.1. Логи контейнеров YARN

Логи контейнеров YARN являются основным источником информации о ходе выполнения задания Spark, поскольку включают в себя вывод операторов логирования в коде задания и используемых библиотеках.

Вывод приложений, запускаемых в контейнерах YARN, включая задания Spark, фиксируются в виде событий Cloud Logging с установленным признаком `log_type: containers`. Вывод можно дополнительно отфильтровать по следуюшим атрибутам:

* `application_id` - идентификатор задания YARN;
* `container_id` - идентификатор контейнера YARN;
* `hostname` - имя хоста кластера Data Proc;
* `yarn_log_type` - имя выходного файла, например:
    *  `stdout` и `stderr` для стандартных потоков вывода и ошибок,
    *  `directory.info` для списка файлов контейнера,
    *  `launch_container.sh` скрипт запуска контейнера,
    *  `prelaunch.out` вывод скрипта подготовки к запуску.

Пример команды для выгрузки логов выполнения конкретного задания, отправляемых в выходные потоки stdout или stderr:

```bash
yc logging read mzinal-dataproc1 \
  --filter 'log_type: containers AND yarn_log_type: stdout stderr AND application_id: application_1705998482380_0013' \
  --since 2024-01-23T10:00:00Z --limit 1000000
```

### 1.2. Системные логи YARN

Логи ресурсного менеджера YARN полезны для диагностики ситуаций вида "задание не запускается", "задание не получает нужного количества ресурсов". Пример:

```bash
yc logging read mzinal-dataproc1 --since 08:50:00 --until 10:20:00 \
  --filter 'log_type: "hadoop-yarn-resourcemanager"'
```

Логи менеджера узла YARN полезны для диагностики аварийных завершений заданий из-за избыточного использования ресурсов. Пример:

```bash
yc logging read mzinal-dataproc1 --since 08:50:00 --until 10:20:00 \
  --filter 'log_type: "hadoop-yarn-nodemanager" AND hostname: "rc1d-dataproc-g-808029-evyc.mdb.yandexcloud.net"'
```

### 1.3. Логи операций Zeppelin

Логи выполнения операций в ноутбуках Zeppelin полезны для ситуаций, когда пользователь работает в Zeppelin. Пример:

```bash
yc logging read mzinal-dataproc1 \
  --filter 'log_type: zeppelin' \
  --since 2024-01-23T08:00:00Z --limit 1000000
```

> [!NOTE]
> Логи Zeppelin не содержат привязки к конкретному выполняемому ноутбуку или заданию Spark, что делает работу с ними неудобной при наличии нескольких конкурентных пользователей Zeppelin.

### 1.4. Логи Livy

Логи компонента Apache Livy, используемого для удалённого запуска операций Spark (включая текущий вариант интеграции с Yandex Data Sphere), записываются в Yandex Cloud Logging с признаками `log_type: livy-request` (запросы к Livy) и `log_type: livy-out` (вывод Livy). При анализе работы заданий обычно нужен именно вывод Livy.

> [!NOTE]
> Логи Livy не содержат вывода операторов логирования прикладного кода задания и используемых им библиотек (в том числе в логах Livy нет сообщений об ошибках, возникших при выполнении логики заданий). Эту информацию можно получить запросом к логам контейнеров YARN, как было описано выше.

Пример запроса:

```bash
yc logging read mzinal-dataproc1 --limit 1000000 --filter 'log_type: livy-out' 
```

### 1.5. Системные логи (syslog)

Записи, поступающие в `syslog` на конкретном узле кластера (обычно нужно при сборе данных на мастер-узле):

```bash
yc logging read mzinal-dataproc1 \
  --filter 'log_type: syslog AND hostname: "rc1d-dataproc-m-ici2e8n3pni3dwby.mdb.yandexcloud.net"' \
  --since 2024-01-23T08:00:00Z --limit 1000000
```

### 1.6. Инициализация кластера и его узлов

Логи работы сервиса `cloud-init`, осуществляющего инициализацию узлов кластера Data Proc, на конкретном узле кластера:

```bash
yc logging read mzinal-dataproc1 \
  --filter 'log_type: cloud-init AND hostname: "rc1d-dataproc-g-808029-ymyh.mdb.yandexcloud.net"'
```

Логи работы скриптов инициализации на конкретном узле кластера:

```bash
yc logging read mzinal-dataproc1 \
  --filter 'log_type: yandex-dataproc-init-actions AND hostname: "rc1d-dataproc-g-808029-omek.mdb.yandexcloud.net"'
```

## 2. События Spark

События Spark накапливаются при работе Spark Master, после чего сохраняются в специальном каталоге в виде файлов формата JSON. Для каждого завершённого задания сохраняется отдельный файл. Отображение событий Spark для завершённых сессий осуществляется с помощью компонента Spark History Server. Детали по работе Spark History Server приведены в [документации на Apache Spark](https://spark.apache.org/docs/3.3.2/monitoring.html).

> [!NOTE]
> События Spark не содержат вывода операторов логирования прикладного кода задания и используемых им библиотек (в том числе в событиях Spark не фиксируются сообщения об ошибках, возникших при выполнении логики заданий). Эту информацию можно получить запросом к логам контейнеров YARN, как было описано выше.

Каталог, в котором сохраняются файлы с событиями заданий, отображается в верхней части основной страницы интерфейса Spark History Server. Для кластеров Yandex Data Proc, в которых активна поддержка HDFS, файлы с событиями сохраняются в HDFS-каталоге `/var/log/spark/apps`. При использовании легковесного кластера Yandex Data Proc, файлы с событями сохраняются в каталоге `/dataproc/hadoop/var/log/spark/apps` бакета Object Storage, связанного с соответствующим кластером. Имена файлов соответствуют идентификаторам соответствующих заданий YARN.

> [!WARNING]  
> Логи задания в Spark History Server могут быть недоступны или быть неполными в случае принудительного завершения задания со стороны YARN. Сбор логов и передача их в Spark History Server выполняются драйвером контекста Spark, и при принудительном завершении драйвера эта операция не может быть выполнена.

Логи завершенного задания можно выгрузить через Web UI компонента Spark History Server, либо путём прямого копирования нужного файла логов. Непосредственный просмотр файла логов затруднён (фактически это последовательность разнородных JSON-записей). Для работы с логами рекомендуется использовать Spark History Server. Может использоваться кластер Data Proc (тот же самый или другой), либо отдельная инсталляция Spark.

Для просмотра логов средствами Spark History Server необходимо:

* поместить файл с логами в рабочий каталог Spark History Server;
* выбрать нужное задание в интерфейсе главной страницы Web UI компонента Spark History Server;
* открыть нужный раздел в интерфейсе работы с логами задания:
    * *Jobs* - содержит информацию о выполнении заданий Spark в сессии, и общую историю выделения и освобождения ресурсов;
    * *Stages* - сведения о выполнении шагов заданий Spark;
    * *Environment* - сводка всех свойств и настроек сессии Spark;
    * *Executors* - статистика по исполнительным процессам сессии Spark;
    * *SQL / DataFrame* - история выполнения операций Spark SQL.

Чтобы просмотреть логи локально, можно использовать локальную инсталляцию Spark:

1. Скачать актуальную версию Apache Spark с [официальной страницы загрузки](https://spark.apache.org/downloads.html).
2. Распаковать дистрибутив Apache Spark в локальный каталог.
3. Скопировать файл `conf/spark-defaults.conf` из шаблона `conf/spark-defaults.conf.template`.
4. Настроить каталог хранения файлов Spark History Server, добавив в файл `conf/spark-defaults.conf` переменную `spark.history.fs.logDirectory`, установив её в путь к существующему каталогу с префиксом `file://`.
5. Скопировать логи заданий для просмотра (при необходимости распаковав их из ZIP-архивов) в каталог, указанный на предыдущем шаге.
6. Запустить Spark History Server, выполнив команду `./sbin/start-history-server.sh`
7. Открыть интерфейс Spark History Server, открыв браузер по адресу http://localhost:18080
