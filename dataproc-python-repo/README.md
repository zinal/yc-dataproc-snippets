# Установка и обновление пакетов Python на кластерах Data Proc

При использовании PySpark часто требуется возможность установки дополнительных пакетов и обновления версий уже установленных пакетов Python на кластерах Data Proc. Решение этой задачи применительно к Yandex Data Proc сопряжено с некоторыми трудностями:
* В отличие от типичных сред "ноутбуков" Jupyter или Zeppelin, активно используемых в среде специалистов по Data Science, кластерная среда Data Proc требует поддержания синхронного состава пакетов и их версий на всех узлах кластера.
* Кластеры Data Proc во многих случаях желательно изолировать от внешних сетей, исключив бесконтрольный доступ в интернет, что затрудняет доступ к стандартным репозиториям пакетов Python.
* Штатные инструменты управления пакетами Python (`conda`, `mamba`) имеют достаточно низкую производительность, особенно при работе с публичными репозиториями, содержащими десятки тысяч пакетов. В результате использование `conda` для установки зависимостей часто приводит к неприемлемому увеличению длительности операций создания или расширения кластеров Data Proc.

Для устранения обозначенных выше трудностей предлагается следующий подход:
* Окружение Python с необходимым составом и версиями пакетов готовится на временном кластере Data Proc.
* Образ сформированного окружения Python сохраняется в бакете объектного хранилища.
* Сформированное окружение Python автоматически клонируется на узлы рабочих кластеров Data Proc без использования менеджера пакетов.

Техническая реализация предлагаемого подхода предполагает выполнение следующей последовательности шагов:
1. Готовим окружение пакетов Python в `/opt/conda` на узле временного кластера.
2. Формируем сжатый образ файлов из `/opt/conda` в формате `squashfs`, и размещаем файл образа в бакете объектного хранилища.
3. Готовим скрипт инициализации, осуществляющий скачивание файла образа и монтирование его в `/opt/conda`.
4. Только для Data Proc 2.0: готовим скрипт инициализации для применения патча к Zeppelin 0.9.0 из-за его несовместимости с обновлениями Python 3.8.
5. Используем подготовленные скрипты инициализации для создания продуктивных кластеров Data Proc.

> **Примечание.** Окружения для образов Data Proc версий 2.0 и 2.1 не совместимы друг с другом из-за различий в версиях системных библиотек. Это ограничение требует подготовки разных образов для использования с образами 2.0 и 2.1.

## 1. Создание среды Python с требуемым составом и версиями библиотек

Для создания среды Python с нужными библиотеками используется временный кластер Data Proc, имеющий доступ в интернет для скачивания дистрибутивов из репозиториев пакетов `conda` и `pip`. Установка необходимых пакетов выполняется в интерактивном режиме, что позволяет уточнить состав необходимых пакетов и их версий и разобраться с возникающими проблемами установки.

Во временном кластере может присутствовать единственный мастер-узел. Количество выделенных ресурсов мастер-узла определяет скорость выполнения операций подготовки среды Python, некоторые из которых используют все доступные процессорные ядра и чувствительны к объему доступной оперативной памяти. Рекомендуется использование не менее 8 vCPU и 16 Гбайт оперативной памяти.

Ориентировочные параметры временного кластера можно посмотреть в [примере скрипта создания кластера](dp-pyenv-prepare.sh). Перед использованием примера скорректируйте настройки в [файле с опциями](dp-pyenv-options.sh), либо укажите настройки непосредственно в своей копии скрипта создания кластера.

После создания кластера необходимо войти клиентом SSH на мастер-узел кластера от имени пользователя `ubuntu`. Дальнейшие действия должны производиться от имени пользователя `root`, переключение пользователя может быть выполнено с помощью команды `sudo su -`.

Окружение Python на узлах кластера Data Proc управляется с помощью инструмента `conda` и размещено в каталоге `/opt/conda`. Перед установкой свежих версий пакетов Python целесообразно обновить уже установленные пакеты, что можно выполнить с помощью следующих команд:

```bash
conda update -c conda-forge -n base --yes conda
conda update -c conda-forge --all --yes
```

> **Примечание.** При возникновении ошибок таймаута сетевого доступа к серверам репозиториев Conda необходимо повторить команду, завершившуюся с ошибкой.

Опционально можно заменить штатный алгоритм разрешения зависимостей `conda` (который работает очень медленно и иногда не может построить план установки) на более современный вариант, [рекомендуемый разработчиками Conda](https://www.anaconda.com/blog/a-faster-conda-for-a-growing-community):

```bash
conda install -c conda-forge -n base --yes conda-libmamba-solver
conda config --set solver libmamba
```

Далее можно установить необходимые дополнительные пакеты Python, например:

```bash
conda install --yes \
  'catboost>0' \
  'lightgbm>0' \
  'nltk>0' \
  'prophet>0' \
  'seaborn>0' \
  'unidecode>0' \
  'psycopg2>0'
```

При установке можно также указать требования к необходимым версиям пакетов, например:

```bash
conda install -c conda-forge --yes \
  'catboost==1.0.6' \
  'lightgbm==3.2.1' \
  'nltk==3.7' \
  'prophet==1.1.2' \
  'seaborn==0.12.2' \
  'unidecode==1.2.0' \
  'psycopg2==2.9.3'
```

Точный состав использованных (успешных) команд по установке пакетов желательно зафиксировать для последующего воспроизведения конфигурации.

На этом этапе на мастер-узле временного кластера Data Proc в каталоге `/opt/conda` сформировано окружение Python, совместимое с Data Proc и содержащее необходимые версии пакетов.

## 2. Формируем сжатый образ файлов окружения

Для формирования образа файлов окружения Python, размещённого в каталоге `/opt/conda`, можно использовать пакет `squashfs-tools`. Его необходимо установить на узел, на котором было подготовлено окружение, путём выполнения команды:

```bash
apt-get install -y squashfs-tools
```

Чтобы поместить все файлы из каталога `/opt/conda` в сжатый файл образа `/CondaImage1.squashfs` можно использовать следующую команду:

```bash
mksquashfs /opt/conda /CondaImage1.squashfs -comp xz
```

В примере команды выше опция `-comp xz` включает использование алгоритма сжатия `xz`, который обычно позволяет создать более компактный файл образа по сравнению с используемым по умолчанию алгоритмом `gzip`.

Сформированный файл образа далее необходимо поместить в бакет объектного хранилища. У сервисного аккаунта, привязанного к временному кластеру Data Proc, должны быть права на запись в этот пакет. Создание каталога в бакете и копирование файла образа можно выполнить с помощью показанных ниже команд:

```bash
sudo -u hdfs hdfs dfs -mkdir s3a://dproc-code/images/
sudo -u hdfs hdfs dfs -copyFromLocal -d /CondaImage1.squashfs s3a://dproc-code/images/
```

На этом этапе подготовленный образ окружения Python был размещён в бакете объектного хранилища. Временный кластер Data Proc можно удалить.

## 3. Скрипт скачивания и монтирования образа

```bash
sudo -u hdfs hdfs dfs -copyToLocal s3a://dproc-code/images/CondaImage1.squashfs /tmp/
mv /tmp/CondaImage1.squashfs /
chown root:root /CondaImage1.squashfs
rm -rf /opt/conda/*
echo '/CondaImage1.squashfs    /opt/conda    squashfs    ro,defaults    0 0' >>/etc/fstab
mount -a
```

Ориентировочное время выполнения - 1 минута.

## 4. Патч для Zeppelin 0.9.0

Образ Data Proc 2.0 включает в себя Zeppelin 0.9.0, в котором присутствует [проблема совместимости](https://github.com/ipython/ipython/issues/11590), не позволяющая обновить версию Python старше 3.8.0. Первоначально исправление было подготовлено [в рамках проекта IPython](https://github.com/ipython/ipython/pull/11593), и включено в более новые версии Zeppelin в виде файла [`zeppelin_python.py`](https://github.com/apache/zeppelin/blob/master/python/src/main/resources/python/zeppelin_python.py).

В случае обновлении среды Python в Data Proc 2.0 дополнительно требуется обновить файл `zeppelin_python.py` в следующих точках:
* каталоге `/usr/lib/zeppelin/interpreter/python/python`;
* архиве `python-interpreter-with-py4j-0.9.0.jar` в каталоге `/usr/lib/zeppelin/interpreter/python`;
* архиве `spark-interpreter-0.9.0.jar` в каталоге `/usr/lib/zeppelin/interpreter/spark`.

Исправленный файл [`zeppelin_python.py`](https://github.com/apache/zeppelin/blob/master/python/src/main/resources/python/zeppelin_python.py) необходимо разместить в бакете объектного хранилища, доступном для чтения от имени сервисной учётной записи, присвоенной кластеру Data Proc.

Предлагаемый пример скрипта инициализации [`init-patch-zeppelin090.sh`](init-patch-zeppelin090.sh) принимает полный путь к исправленному файлу `zeppelin_python.py` в качестве аргумента (например, `s3a://dproc-code/images/zeppelin_python.py`), и заменяет старые копии этого файла на узле кластера Data Proc.

## 5. Пример создания продуктивного кластера Data Proc

