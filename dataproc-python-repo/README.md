# Установка и обновление пакетов Python на кластерах Data Proc

При использовании PySpark часто требуется установка дополнительных пакетов Python и обновление версий уже установленных пакетов Python на кластерах [Yandex Data Proc](https://cloud.yandex.ru/services/data-proc). Окружение Python на узлах кластера Data Proc управляется с помощью менеджера пакетов Conda и размещено в каталоге `/opt/conda`.

Решение задачи обновления среды Python на кластерах Data Proc сопряжено с некоторыми трудностями, с которыми сталкиваются пользователи:
* В отличие от типичных сред "ноутбуков" Jupyter или Zeppelin, активно используемых в среде специалистов по Data Science, кластерная среда Data Proc требует поддержания синхронного состава пакетов и их версий на всех узлах кластера.
* Кластеры Data Proc во многих случаях желательно изолировать от внешних сетей, исключив бесконтрольный доступ в интернет, что затрудняет доступ к стандартным репозиториям пакетов Python.
* Менеджер пакетов Conda имеет достаточно низкую производительность, особенно при работе с публичными репозиториями, содержащими десятки тысяч пакетов. В результате использование Conda для автоматической установки пакетов на узлах часто приводит к неприемлемому увеличению длительности и сбоям операций создания или расширения кластеров Data Proc.

Для устранения обозначенных выше трудностей предлагается следующий подход:
* Окружение Python с необходимым составом и версиями пакетов готовится на временном кластере Data Proc.
* Образ сформированного окружения Python сохраняется в бакете объектного хранилища.
* Сформированное окружение Python автоматически клонируется на узлы рабочих кластеров Data Proc без использования менеджера пакетов.

Предлагаемый подход можно реализовать путём выполнения следующей последовательности шагов:
1. Готовим окружение пакетов Python в `/opt/conda` на узле временного кластера.
2. Формируем сжатый образ файлов из `/opt/conda` в формате `squashfs`, и размещаем образ в бакете объектного хранилища.
3. Готовим скрипт инициализации, осуществляющий скачивание образа из бакета и монтирование его в `/opt/conda` на узлах кластера Data Proc.
4. Только для образа Data Proc 2.0: готовим скрипт инициализации для применения патча к Zeppelin 0.9.0 из-за его несовместимости с обновлениями Python 3.8.
5. Используем подготовленные скрипты инициализации для создания продуктивных кластеров Data Proc.

> **Примечание.** Окружения Python для образов Data Proc версий 2.0 и 2.1 не совместимы друг с другом из-за различий в версиях системных библиотек. Это ограничение требует подготовки разных образов окружений Python для использования с образами Data Proc 2.0 и 2.1.

## 1. Создание среды Python с требуемым составом и версиями библиотек

Для создания среды Python с нужными библиотеками используется временный кластер Data Proc, имеющий доступ в интернет для скачивания дистрибутивов из репозиториев пакетов `conda` и `pip`. Установка необходимых пакетов выполняется в интерактивном режиме, что позволяет уточнить состав необходимых пакетов и их версий и разобраться с возникающими проблемами установки.

Временный кластер может состоять из единственного мастер-узла. Количество выделенных ресурсов мастер-узла определяет скорость выполнения операций подготовки среды Python, некоторые из которых используют все доступные процессорные ядра и чувствительны к объему доступной оперативной памяти. Рекомендуется использование не менее 8 vCPU и 16 Гбайт оперативной памяти.

Ориентировочные параметры временного кластера можно посмотреть в [примере скрипта создания кластера](dp-pyenv-prepare.sh). Перед использованием примера скорректируйте настройки в [файле с опциями](dp-pyenv-options.sh), либо укажите настройки непосредственно в своей копии скрипта создания кластера.

После создания кластера необходимо войти клиентом SSH на мастер-узел кластера от имени пользователя `ubuntu`. Дальнейшие действия должны производиться от имени пользователя `root`, переключение пользователя может быть выполнено с помощью команды `sudo su -`.

> **Примечание.** При выполнении команд, описанных в этом разделе, в случае возникновении ошибок таймаута сетевого доступа к серверам репозиториев Conda необходимо повторить команду, завершившуюся с ошибкой.

Менеджер пакетов Conda перед началом дальнейших действий стоит обновить, это можно сделать следующей командой:

```bash
conda update -c conda-forge -n base --yes conda
```

Опционально можно заменить штатный алгоритм разрешения зависимостей Conda (который работает очень медленно и иногда не может построить план установки) на более современный вариант, [рекомендуемый разработчиками Conda](https://www.anaconda.com/blog/a-faster-conda-for-a-growing-community):

```bash
conda install -c conda-forge -n base --yes conda-libmamba-solver
conda config --set solver libmamba
```

Перед установкой свежих версий пакетов Python иногда целесообразно обновить все уже установленные пакеты, что можно выполнить с помощью следующих команд:

```bash
conda update -c conda-forge --all --yes
```

Далее можно установить необходимые дополнительные пакеты Python, например:

```bash
conda install --yes \
  'catboost>0' \
  'lightgbm>0' \
  'nltk>0' \
  'prophet>0' \
  'seaborn>0' \
  'unidecode>0' \
  'psycopg2>0'
```

При установке можно также указать требования к необходимым версиям пакетов, например:

```bash
conda install -c conda-forge --yes \
  'catboost==1.0.6' \
  'lightgbm==3.2.1' \
  'nltk==3.7' \
  'prophet==1.1.2' \
  'seaborn==0.12.2' \
  'unidecode==1.2.0' \
  'psycopg2==2.9.3'
```

Точный состав использованных (успешных) команд по установке пакетов желательно зафиксировать для последующего воспроизведения конфигурации.

На этом этапе на мастер-узле временного кластера Data Proc в каталоге `/opt/conda` сформировано окружение Python, совместимое с Data Proc и содержащее необходимые версии пакетов.

## 2. Формируем сжатый образ файлов окружения

Для формирования образа файлов окружения Python, размещённого в каталоге `/opt/conda`, можно использовать пакет `squashfs-tools`. Его необходимо установить на узел, на котором было подготовлено окружение, путём выполнения команды:

```bash
apt-get install -y squashfs-tools
```

Чтобы поместить все файлы из каталога `/opt/conda` в сжатый файл образа `/CondaImage1.squashfs` можно использовать следующую команду:

```bash
mksquashfs /opt/conda /CondaImage1.squashfs -comp xz
```

В примере команды выше опция `-comp xz` включает использование алгоритма сжатия `xz`, который обычно позволяет создать более компактный файл образа по сравнению с используемым по умолчанию алгоритмом `gzip`.

Сформированный файл образа далее необходимо поместить в бакет объектного хранилища. У сервисного аккаунта, привязанного к временному кластеру Data Proc, должны быть права на запись в этот пакет. Создание каталога в бакете и копирование файла образа можно выполнить с помощью показанных ниже команд:

```bash
sudo -u hdfs hdfs dfs -mkdir s3a://dproc-code/images/
sudo -u hdfs hdfs dfs -copyFromLocal -d /CondaImage1.squashfs s3a://dproc-code/images/
```

На этом этапе подготовленный образ окружения Python был размещён в бакете объектного хранилища. Временный кластер Data Proc можно удалить.

## 3. Скрипт скачивания и монтирования образа

Пример скрипта инициализации Data Proc для скачивания и монтирования образа из бакета объектного хранилища [доступен в репозитории](init-conda-squashfs.sh). Ниже приводится разбор выполняемых в скрипте операций.

Полный путь к образу окружения Python передаётся в скрипт через аргумент командной строки. Первоначальное скачивание образа производится скриптом во временный каталог с помощью команды, эквивалентной приведённому ниже примеру:

```bash
sudo -u hdfs hdfs dfs -copyToLocal s3a://dproc-code/images/CondaImage1.squashfs /tmp/
```

Параллельно со скачиванием файла в фоне происходит удаление текущего содержимого каталога `/opt/conda`, что позволяет освободить часть пространства на диске узла Data Proc:

```bash
rm -rf /opt/conda/* &
```

Далее происходит перемещение скачанного файла в корень файловой системы, установка владельца и полномочий.

```bash
mv /tmp/CondaImage1.squashfs /
chown root:root /CondaImage1.squashfs
chmod 444 /CondaImage1.squashfs
```

Для настройки монтирования образа при запуске узла кластера требуется добавить соответствующую запись в файл `/etc/fstab`:

```bash
echo '/CondaImage1.squashfs    /opt/conda    squashfs    ro,defaults    0 0' >>/etc/fstab
```

Далее выполняется монтирование образа:

```bash
mount /opt/conda
```

Подготовленный скрипт инициализации необходимо поместить в бакет объектного хранилища, доступный на чтение для сервисной учётной записи, присваиваемой продуктивным кластерам Data Proc.

## 4. Патч для Zeppelin 0.9.0

Образ Data Proc 2.0 включает в себя Zeppelin 0.9.0, в котором присутствует [проблема совместимости](https://github.com/ipython/ipython/issues/11590), не позволяющая обновить версию Python старше 3.8.0. Первоначально исправление было подготовлено [в рамках проекта IPython](https://github.com/ipython/ipython/pull/11593), и включено в более новые версии Zeppelin в виде файла [`zeppelin_python.py`](https://github.com/apache/zeppelin/blob/master/python/src/main/resources/python/zeppelin_python.py).

В случае обновлении среды Python в Data Proc 2.0 дополнительно требуется обновить файл `zeppelin_python.py` в следующих точках:
* каталоге `/usr/lib/zeppelin/interpreter/python/python`;
* архиве `python-interpreter-with-py4j-0.9.0.jar` в каталоге `/usr/lib/zeppelin/interpreter/python`;
* архиве `spark-interpreter-0.9.0.jar` в каталоге `/usr/lib/zeppelin/interpreter/spark`.

Исправленный файл [`zeppelin_python.py`](https://github.com/apache/zeppelin/blob/master/python/src/main/resources/python/zeppelin_python.py) необходимо разместить в бакете объектного хранилища, доступном для чтения от имени сервисной учётной записи, присвоенной кластеру Data Proc.

Предлагаемый пример скрипта инициализации [`init-patch-zeppelin090.sh`](init-patch-zeppelin090.sh) принимает полный путь к исправленному файлу `zeppelin_python.py` в качестве аргумента (например, `s3a://dproc-code/images/zeppelin_python.py`), и заменяет старые копии этого файла на узле кластера Data Proc. Скрипт необходимо поместить в бакет объектного хранилища, доступный на чтение для сервисной учётной записи, присваиваемой продуктивным кластерам Data Proc.

## 5. Пример создания продуктивного кластера Data Proc

При создании продуктивных кластеров Data Proc на основе сформированного окружения Python необходимо:
* обеспечить доступ на чтение бакетов со скриптами инициализации и используемым файлом образа для сервисной учётной записи, присваиваемой кластеру;
* указать скрипты инициализации в настройках кластера, передав в аргументах полный путь к файлу образа и полный путь к исправленному файлу `zeppelin_python.py`.

Возможный пример передачи параметров описан в [примере скрипта создания кластера](dp-pyenv-cluster.sh). Перед использованием примера скорректируйте настройки в [файле с опциями](dp-pyenv-options.sh), либо укажите настройки непосредственно в своей копии скрипта создания кластера.

Проверить работоспособность окружения Python на созданном кластере Data Proc можно с помощью любого задания PySpark. При наличии в кластере сервиса Zeppelin можно воспользоваться встроенным примером ноутбука `Spark Tutorial / Spark SQL (PySpark)`.