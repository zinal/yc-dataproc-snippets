# 1. Общие сведения о выполнении запросов Spark SQL в среде Yandex Data Proc

* В каждый момент времени на кластере может быть запущено несколько приложений (*application*).
* Каждое из приложений может находиться в ожидании, либо выполнять один или несколько заданий (*job*). Приведённое далее описание относится к определённому виду заданий, а именно заданиям Spark SQL (выполнение SQL запросов средствами Spark).
* Каждое из заданий состоит из набора операций (*task*), которые могут выполняться как параллельно, так и последовательно в зависимости от плана выполнения. Параллельно выполняемые операции группируются в стадии (*stages*).
* Задания, запросы и операции могут находиться в разных состояниях, в том числе - ожидание выполнения, выполнение, завершено успешно, завершено с ошибкой.

В зависимости от настроек (режим планировщика Spark) задания в рамках приложения могут выполняться последовательно (FIFO), либо параллельно (FAIR), при этом параллельное выполнение требует дополнительной настройки на уровне системы и конкретного задания. Обычно удобнее запускать параллельные задания в отдельных приложениях Spark, и ограничиться последовательным выполнением заданий внутри каждого из приложений, во избежание усложнения настроек.

Операции выполняются в рамках исполнителей (*executors*), каждый из которых представляет собой программу, запускаемую на одном из узлов кластера и использующую для своей работы определённое количество вычислительных ресурсов (процессорных ядер, оперативной памяти). Количество параллельно запускаемых операций определяется потребностями выполняемых запросов, а также доступными ресурсами кластера.

При использовании стандартных настроек Yandex Data Proc ресурсы выделяются на выполняемые задания динамически, по мере запуска пользователем соответствующих запросов Spark SQL. Существует ряд настроек, влияющих на выделение ресурсов, в том числе влияющих на "размер" каждого из исполнителей (выделяемые количество ядер и объём оперативной памяти), и, как следствие, на доступное количество исполнителей в рамках кластера.

Скорость выполнения конкретного запроса зависит от того, какие конкретно вычислительные ресурсы доступны для выполнения его операций, т.е. сколько удалось выделить исполнителей, с учётом потребления всех заданий, запущенных на том же самом кластере.

# 2. Сбор базовой диагностической информации по запросам Spark SQL

Первичная диагностика проблем с производительностью запросов Spark SQL сводится к следующей последовательности действий:
1. проверке доступных и фактически выделенных вычислительных ресурсов;
2. проверке продолжительности выполнения отдельных операций в рамках запроса, с целью поиска "узких мест";
3. получению и анализу плана выполнения запроса.

Для сбора диагностической информации необходим доступ к кластеру Yandex Data Proc, устанавливаемый ролью `dataproc.user` на уровне папки, содержащей соответствующий кластер.

Ссылки на инструменты диагностики представлены на странице информации о кластере (см. рисунок ниже):
1. YARN Resource Manager Web UI - инструмент для просмотра списка и состояния заданий, запущенных на кластере;
2. Spark History Server Web UI - инструмент для просмотра детальной информации о заданиях Spark.

![Страница информации о кластере Data Proc](images/01-service.png)

## 2.1 Проверить состав запущенных на кластере приложений

Информация о работающих на кластере приложениях, включая историю выполнения, доступна из интерфейса YARN Resource Manager UI, раздел "Applications", показанном на скриншоте ниже.

Внимание: скриншот широкий (возможно, с горизонтальной прокруткой).

![Страница информации о запущенных приложениях](images/02-rm-apps.png)

* Для каждого запущенного приложения можно перейти к странице детальной информации (ссылка "Application Master").
* По завершённым приложениям можно просмотреть историческую информацию (ссылка "History").
* По всем отображаемым приложениям можно просмотреть логи (ссылка application_... в левой части скриншота).

Запущенным приложением может быть сессия Spark, созданная из ноутбука Zeppelin, из ноутбука Yandex DataSphere, из интерактивного интерпретатора `spark-sql`, или каким-то другим способом.

Если приложение запланировано к выполнению, но не запущено, можно проверить состояние очередей планирования ресурсов, чтобы определить причину блокировки. Соответствующая информация доступна в разделе "Scheduler", показанном на скриншоте ниже.

Внимание: скриншот широкий (возможно, с горизонтальной прокруткой).

![Страница информации об очередях выполнения](images/02-rm-sched.png)

## 2.2 Информация о работающем приложении Spark

### 2.2.1 Общая информация о работающем приложении Spark

Для работающего приложения Spark (например, для открытой сессии Spark, связанной с ноутбуком Zeppelin) детальную информацию можно просмотреть по ссылке "Application Master" из YARN Resource Manager UI, как показано на скриншотах в предыдущем разделе.

Общий вид главной страницы детальной информации о приложении Spark показан на скриншоте ниже.

![Общая информация о задании Spark](images/03-spark-context-main.png)

Доступна следующая информация:
* перечень активных заданий (*Active Jobs*), т.е. в нашем случае Spark SQL запросы, которые работают либо ожидают начала выполнения;
* завершённые ранее задания (*Completed Jobs*);
* время запуска заданий и продолжительность выполнения;
* количество успешно выполненных и запланированных операций (*tasks*).

Если раскрыть раздел "Events Timeline" в верхней части страницы, то можно просмотреть в графическом виде историю выполнения заданий, выделения и освобождения вычислительных ресурсов, как показано на скриншоте ниже.

![Раздел Events Timeline](images/08-spark-context-timeline.png)

### 2.2.2 Выделенные ресурсы для работы приложения Spark

Сведения о выделенных для работы приложения Spark вычислительных ресурсов представлены в разделе "Executors" (см. снимок экрана ниже).

![Ресурсы для работы приложения Spark](images/04-spark-context-executors.png)

Доступна следующая информация:
* количество, состав и состояние исполнителей;
* количество доступных каждому исполнителю процессорных ядер и оперативной памяти;
* количество выполняемых и завершённых операций (*tasks*);
* затраты времени, включая отдельно время сборки мусора (*GC Time*).

Высокая доля времени сборки мусора может свидетельствовать о нехватке оперативной памяти, а также о возможной необходимости использования специальных настроек сборки мусора (например, иногда рекомендуют `spark:spark.executor.extraJavaOptions: -XX:+UseG1GC`).

### 2.2.3 Закэшированные данные

Использование оперативной памяти исполнителей для кэширования таблиц можно оценить в разделе "Storage", как показано на скриншоте ниже.

![Закешированные таблицы Spark](images/05-spark-context-storage.png)

Для каждой таблицы отображается информация об используемой оперативной памяти и пространстве на локальном диске исполнителей, а также прогресс выполнения операции кэширования.

Также по каждой таблице можно просмотреть детализацию со статистикой по разделам таблицы, перейдя по ссылке с именем таблицы.

## 2.3 Сбор информации для завершённого приложения Spark

Большая часть информации, доступная для работающего приложения Spark, доступна и для уже завершённых приложений. Доступ к соответствующим данным осуществляется через ссылку "Spark History Server Wev UI" на странице общей информации о кластере Data Proc.
