# Общие сведения о выполнении Spark SQL операций на кластерах Data Proc

* В каждый момент времени на кластере может быть запущено несколько заданий.
* Каждое из заданий может находиться в ожидании, либо выполнять один или несколько запросов.
* Каждый из запросов состоит из набора стадий, которые могут выполняться как параллельно, так и последовательно в зависимости от плана выполнения.
* Задания, запросы и стадии могут находиться в разных состояниях, в том числе - ожидание выполнения, выполнение, завершено успешно, завершено с ошибкой.

Каждая из конкурентно выполняемых стадий запросов запускается на одном из узлов кластера и получает свою долю вычислительных ресурсов - указанное в настройках задания количество ядер и оперативной памяти. Количество параллельно запускаемых стадий определяется потребностями выполняемых запросов, а также доступными ресурсами кластера.

Скорость выполнения конкретного запроса зависит от того, какие конкретно вычислительные ресурсы доступны для выполнения его стадий, с учётом потребления всех заданий, запущенных на том же самом кластере.

# Сбор диагностической информации о задании Spark в среде Yandex Data Proc

Для сбора диагностической информации необходим доступ к кластеру Yandex Data Proc, устанавливаемый ролью `dataproc.user` на уровне папки, содержащей соответствующий кластер.

Ссылки на инструменты диагностики представлены на странице информации о кластере (см. рисунок ниже):
1. YARN Resource Manager Web UI - инструмент для просмотра списка и состояния заданий, запущенных на кластере;
2. Spark History Server Web UI - инструмент для просмотра детальной информации о заданиях Spark.

![Страница информации о кластере Data Proc](images/01-service.png)

## Проверить состав запущенных на кластере заданий


## Сбор информации для работающего Spark контекста

